{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Load your dataframe here\n",
    "# df = pd.read_csv('your_file.csv')\n",
    "df=pd.read_csv(\"C:\\\\Users\\\\saipr\\\\Downloads\\\\Combined Data.csv (1)\\\\Combined Data.csv\")\n",
    "\n",
    "df=df.dropna(subset=['statement'])\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>statement</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>oh my gosh</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I've shifted my focus to something else but I'...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I'm restless and restless, it's been a month n...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53038</th>\n",
       "      <td>53038</td>\n",
       "      <td>Nobody takes me seriously I’ve (24M) dealt wit...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53039</th>\n",
       "      <td>53039</td>\n",
       "      <td>selfishness  \"I don't feel very good, it's lik...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53040</th>\n",
       "      <td>53040</td>\n",
       "      <td>Is there any way to sleep better? I can't slee...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53041</th>\n",
       "      <td>53041</td>\n",
       "      <td>Public speaking tips? Hi, all. I have to give ...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53042</th>\n",
       "      <td>53042</td>\n",
       "      <td>I have really bad door anxiety! It's not about...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52681 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                          statement   status\n",
       "0               0                                         oh my gosh  Anxiety\n",
       "1               1  trouble sleeping, confused mind, restless hear...  Anxiety\n",
       "2               2  All wrong, back off dear, forward doubt. Stay ...  Anxiety\n",
       "3               3  I've shifted my focus to something else but I'...  Anxiety\n",
       "4               4  I'm restless and restless, it's been a month n...  Anxiety\n",
       "...           ...                                                ...      ...\n",
       "53038       53038  Nobody takes me seriously I’ve (24M) dealt wit...  Anxiety\n",
       "53039       53039  selfishness  \"I don't feel very good, it's lik...  Anxiety\n",
       "53040       53040  Is there any way to sleep better? I can't slee...  Anxiety\n",
       "53041       53041  Public speaking tips? Hi, all. I have to give ...  Anxiety\n",
       "53042       53042  I have really bad door anxiety! It's not about...  Anxiety\n",
       "\n",
       "[52681 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "Normal                  16343\n",
       "Depression              15404\n",
       "Suicidal                10652\n",
       "Anxiety                  3841\n",
       "Bipolar                  2777\n",
       "Stress                   2587\n",
       "Personality disorder     1077\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saipr\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1054/1054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 58ms/step - accuracy: 0.5376 - loss: 1.4708 - val_accuracy: 0.6312 - val_loss: 0.8663\n",
      "Epoch 2/10\n",
      "\u001b[1m1054/1054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 40ms/step - accuracy: 0.6410 - loss: 0.8543 - val_accuracy: 0.6842 - val_loss: 0.8026\n",
      "Epoch 3/10\n",
      "\u001b[1m1054/1054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 42ms/step - accuracy: 0.7234 - loss: 0.7253 - val_accuracy: 0.6994 - val_loss: 0.7772\n",
      "Epoch 4/10\n",
      "\u001b[1m1054/1054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 43ms/step - accuracy: 0.7581 - loss: 0.6607 - val_accuracy: 0.7229 - val_loss: 0.7632\n",
      "Epoch 5/10\n",
      "\u001b[1m1054/1054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 44ms/step - accuracy: 0.7915 - loss: 0.6026 - val_accuracy: 0.7182 - val_loss: 0.7943\n",
      "Epoch 6/10\n",
      "\u001b[1m1054/1054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 42ms/step - accuracy: 0.8057 - loss: 0.5577 - val_accuracy: 0.7299 - val_loss: 0.7380\n",
      "Epoch 7/10\n",
      "\u001b[1m1054/1054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 43ms/step - accuracy: 0.8190 - loss: 0.5283 - val_accuracy: 0.7369 - val_loss: 0.7410\n",
      "Epoch 8/10\n",
      "\u001b[1m1054/1054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 45ms/step - accuracy: 0.8343 - loss: 0.4943 - val_accuracy: 0.7300 - val_loss: 0.7490\n",
      "Epoch 9/10\n",
      "\u001b[1m1054/1054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 43ms/step - accuracy: 0.8425 - loss: 0.4729 - val_accuracy: 0.7227 - val_loss: 0.8145\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.7400 - loss: 0.7179\n",
      "Test Loss: 0.7186583876609802\n",
      "Test Accuracy: 0.7390149235725403\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Load your dataframe here\n",
    "# df = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Extract features and labels\n",
    "texts = df['statement'].values\n",
    "labels = df['status'].values\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "one_hot_labels = to_categorical(encoded_labels)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, one_hot_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer(num_words=10000)  # Adjust the num_words parameter as needed\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad sequences to ensure uniform input length\n",
    "max_sequence_length = 100  # Adjust as needed\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_sequence_length)\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000, output_dim=128, input_length=max_sequence_length))\n",
    "model.add(LSTM(units=64, return_sequences=False, kernel_regularizer=l2(0.01)))  # L2 regularization\n",
    "model.add(Dropout(0.6))  # Increased dropout rate\n",
    "model.add(Dense(units=len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping and model checkpoint callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, save_weights_only=False)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_padded, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "# Load the best model\n",
    "model.load_weights('best_model.keras')\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step\n",
      "Text: \"Balancing work, family, and personal responsibilities is leaving me feeling drained and anxious all the time\"\n",
      "Predicted Label: Anxiety\n",
      "\n",
      "Text: \"I have had a few dreams where something is trying to push me off a cliff, i always struggling trying to stay on for a bit but then just give up and jump off because id rather die than struggle to live. my day thoughts are taking over my night thoughts...\"\n",
      "Predicted Label: Suicidal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming you have the following variables already set up:\n",
    "# tokenizer - the Tokenizer object used for training\n",
    "# max_sequence_length - the maximum length of the sequences\n",
    "# model - the trained model or a path to the saved model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('best_model.keras')\n",
    "\n",
    "# Example new texts for prediction\n",
    "new_texts = [\n",
    "    \"Balancing work, family, and personal responsibilities is leaving me feeling drained and anxious all the time\",\n",
    "    \"I have had a few dreams where something is trying to push me off a cliff, i always struggling trying to stay on for a bit but then just give up and jump off because id rather die than struggle to live. my day thoughts are taking over my night thoughts...\"\n",
    "]\n",
    "\n",
    "# Tokenize and pad the new texts\n",
    "X_new_sequences = tokenizer.texts_to_sequences(new_texts)\n",
    "X_new_padded = pad_sequences(X_new_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_new_padded)\n",
    "\n",
    "# Convert predictions to labels\n",
    "# If using one-hot encoding, you may need to use np.argmax to get the predicted class index\n",
    "predicted_class_indices = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Decode the predicted class indices to labels\n",
    "# Assuming label_encoder is already fit on the original labels\n",
    "predicted_labels = label_encoder.inverse_transform(predicted_class_indices)\n",
    "\n",
    "# Print the predictions\n",
    "for text, label in zip(new_texts, predicted_labels):\n",
    "    print(f'Text: \"{text}\"\\nPredicted Label: {label}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model and vectorizer\n",
    "joblib.dump(model, 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save tokenizer and label encoder\n",
    "joblib.dump(tokenizer, 'tokenizer.pkl')\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('best_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
